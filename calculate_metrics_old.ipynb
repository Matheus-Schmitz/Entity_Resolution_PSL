{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qualified-executive",
   "metadata": {},
   "source": [
    "## Load Truth and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-framework",
   "metadata": {},
   "source": [
    "**Ground Truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_truth.shape: (598, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7012</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1  2\n",
       "0  7012  1050  0\n",
       "1    46    20  0\n",
       "2    26    72  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth = pd.read_csv('labeled_sameMovie_truth.txt', sep='\\t', header=None)\n",
    "print(f'df_truth.shape: {df_truth.shape}')\n",
    "df_truth.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perfect-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 598/598 [00:00<00:00, 11184.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dict with double index\n",
    "dict_truth = {}\n",
    "for idx, (idx_a, idx_b, truth) in tqdm(df_truth.iterrows(), total=df_truth.shape[0]):\n",
    "    dict_truth[(int(idx_a), int(idx_b))] = int(truth)\n",
    "len(dict_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrong-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 598/598 [00:00<00:00, 6520.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_truth_inverse = {0:[], 1:[]}\n",
    "for idx, (idx_a, idx_b, truth) in tqdm(df_truth.iterrows(), total=df_truth.shape[0]):\n",
    "    if truth >= 0.5:\n",
    "        dict_truth_inverse[1].append((int(idx_a), int(idx_b)))\n",
    "    else:\n",
    "        dict_truth_inverse[0].append((int(idx_a), int(idx_b)))\n",
    "len(dict_truth_inverse[0]) + len(dict_truth_inverse[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-genesis",
   "metadata": {},
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "combined-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pred.shape: (33148, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3377</td>\n",
       "      <td>2859</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10262</td>\n",
       "      <td>10262</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3247</td>\n",
       "      <td>7671</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1         2\n",
       "0   3377   2859  0.000665\n",
       "1  10262  10262  1.000000\n",
       "2   3247   7671  0.000242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv('./inferred-predicates_hw8/SAMEMOVIE.txt', sep='\\t', header=None)\n",
    "print(f'df_pred.shape: {df_pred.shape}')\n",
    "df_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legal-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 33148/33148 [00:02<00:00, 11286.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pred_filtered.shape: (267, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3410</td>\n",
       "      <td>3410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3317</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3353</td>\n",
       "      <td>3353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1  2\n",
       "0  3410  3410  1\n",
       "1  3317  3435  0\n",
       "2  3353  3353  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the predictions which are in the ground truth\n",
    "labeled_candidates = set(zip(df_truth[0], df_truth[1]))\n",
    "df_pred_filtered = pd.DataFrame(columns = [0, 1, 2])\n",
    "\n",
    "for idx, row in tqdm(df_pred.iterrows(), total=df_pred.shape[0]):\n",
    "    if (int(row[0]), int(row[1])) in labeled_candidates or (int(row[1]), int(row[0])) in labeled_candidates:\n",
    "        df_pred_filtered = df_pred_filtered.append({0: int(row[0]),\n",
    "                                                    1: int(row[1]),\n",
    "                                                    2: int(row[2])},\n",
    "                                                   ignore_index=True)\n",
    "\n",
    "print(f'df_pred_filtered.shape: {df_pred_filtered.shape}')\n",
    "df_pred_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-mason",
   "metadata": {},
   "source": [
    "The size of the my DataFrame with predictions is smaller than that of the DataFrame with the truth because the truth DataFrame containts many true non-matches, which weren't even generated by my code as nearly all of those non-matches didn't even fall within the same block, making it impossible for me to even predict their non-matchess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "square-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 267/267 [00:00<00:00, 9889.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dict with double index\n",
    "dict_pred = {}\n",
    "for idx, (idx_a, idx_b, call) in tqdm(df_pred.iterrows(), total=df_pred.shape[0]):\n",
    "    dict_pred[(int(idx_a), int(idx_b))] = 1 if call >= 0.5 else 0\n",
    "len(dict_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "little-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then for all keys in the truth which were not predicted by my model, add them with a prediction for non-match\n",
    "for key in dict_truth.keys():\n",
    "    if key not in dict_pred.keys():\n",
    "        dict_pred[key] = 0\n",
    "len(dict_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "chronic-induction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 267/267 [00:00<00:00, 9206.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pred_inverse = {0:[], 1:[]}\n",
    "for idx, (idx_a, idx_b, call) in tqdm(df_pred_filtered.iterrows(), total=df_pred_filtered.shape[0]):\n",
    "    if call >= 0.5:\n",
    "        dict_pred_inverse[1].append((int(idx_a), int(idx_b)))\n",
    "    else:\n",
    "        dict_pred_inverse[0].append((int(idx_a), int(idx_b)))\n",
    "len(dict_pred_inverse[0]) + len(dict_pred_inverse[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "informed-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then for all keys in the truth which were not predicted by my model, add them with a prediction for non-match\n",
    "for (idx_a, idx_b) in dict_truth_inverse[0]:\n",
    "    if (idx_a, idx_b) not in dict_pred_inverse[0]:\n",
    "        dict_pred_inverse[0].append((idx_a, idx_b))\n",
    "len(dict_pred_inverse[0]) + len(dict_pred_inverse[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "preliminary-assessment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, value in dict_pred.items():\n",
    "    if key not in dict_pred_inverse.values():\n",
    "        dict_pred_inverse[value].append(key)\n",
    "len(dict_pred_inverse[0]) + len(dict_pred_inverse[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "human-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, value in dict_pred_inverse.items():\n",
    "    if value not in dict_pred.values():\n",
    "        dict_pred[value] = key\n",
    "len(dict_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-catering",
   "metadata": {},
   "source": [
    "## Binary Classification Metrics For Class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-humor",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "\"Of all calls I made, how many were correctly made?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banned-planner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  409\n",
      "FP:   58\n",
      "Precision: 0.87580\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "# dict_pred_inverse[1] = all the calls I made\n",
    "for match in dict_pred_inverse[0]: \n",
    "    if dict_truth.get(match) == 0:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FP += 1\n",
    "        \n",
    "precision_0 = TP / (TP + FP)\n",
    "\n",
    "print(f'TP: {TP:>4}')\n",
    "print(f'FP: {FP:>4}')\n",
    "print(f'Precision: {precision_0:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-lambda",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "\"Of all calls I should have made, how many did I make?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arranged-ensemble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  407\n",
      "FN:    2\n",
      "Recall: 0.99511\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FN = 0\n",
    "\n",
    "# dict_truth_inverse[1] = all the calls I should have made\n",
    "for match in dict_truth_inverse[0]: \n",
    "    if dict_pred.get(match) == 0:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FN += 1\n",
    "        \n",
    "recall_0 = TP / (TP + FN)\n",
    "\n",
    "print(f'TP: {TP:>4}')\n",
    "print(f'FN: {FN:>4}')\n",
    "print(f'Recall: {recall_0:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-helicopter",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "friendly-discharge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.93165\n"
     ]
    }
   ],
   "source": [
    "F1_0 = (2 * precision_0 * recall_0) / (precision_0 + recall_0)\n",
    "print(f'F1 Score: {F1_0:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-roller",
   "metadata": {},
   "source": [
    "## Binary Classification Metrics For Class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-steering",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "\"Of all calls I made, how many were correctly made\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nervous-canyon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  171\n",
      "FP:    2\n",
      "Precision: 0.98844\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "# dict_pred_inverse[1] = all the calls I made\n",
    "for match in dict_pred_inverse[1]: \n",
    "    if dict_truth.get(match) == 1:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FP += 1\n",
    "        \n",
    "precision_1 = TP / (TP + FP)\n",
    "\n",
    "print(f'TP: {TP:>4}')\n",
    "print(f'FP: {FP:>4}')\n",
    "print(f'Precision: {precision_1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-accounting",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "\"Of all calls I should have made, how many did I make?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "studied-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  171\n",
      "FN:   18\n",
      "Recall: 0.90476\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FN = 0\n",
    "\n",
    "# dict_truth_inverse[1] = all the calls I should have made\n",
    "for match in dict_truth_inverse[1]: \n",
    "    if dict_pred.get(match) == 1:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FN += 1\n",
    "        \n",
    "recall_1 = TP / (TP + FN)\n",
    "\n",
    "print(f'TP: {TP:>4}')\n",
    "print(f'FN: {FN:>4}')\n",
    "print(f'Recall: {recall_1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-brown",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ideal-explanation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.94475\n"
     ]
    }
   ],
   "source": [
    "F1_1 = (2 * precision_1 * recall_1) / (precision_1 + recall_1)\n",
    "print(f'F1 Score: {F1_1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-fourth",
   "metadata": {},
   "source": [
    "Matheus Schmitz\n",
    "\n",
    "USC ID: 5039286453"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
